<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Econometrics and Free Software</title>
    <link>/</link>
    <description>Recent content on Econometrics and Free Software</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 27 Aug 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Why I find tidyeval useful</title>
      <link>/blog/2017-08-27-why_tidyeval/</link>
      <pubDate>Sun, 27 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-08-27-why_tidyeval/</guid>
      <description>First thing’s first: maybe you shouldn’t care about tidyeval. Maybe you don’t need it. If you exclusively work interactively, I don’t think that learning about tidyeval is important. I can only speak for me, and explain to you why I personally find tidyeval useful.
I wanted to write this blog post after reading this twitter thread and specifically this question.
Mara Averick then wrote this blogpost linking to 6 other blog posts that give some tidyeval examples.</description>
    </item>
    
    <item>
      <title>tidyr::spread() and dplyr::rename_at() in action</title>
      <link>/blog/2017-07-27-spread_rename_at/</link>
      <pubDate>Thu, 27 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-07-27-spread_rename_at/</guid>
      <description>I was recently confronted to a situation that required going from a long dataset to a wide dataset, but with a small twist: there were two datasets, which I had to merge into one. You might wonder what kinda crappy twist that is, right? Well, let’s take a look at the data:
data1; data2 ## # A tibble: 20 x 4 ## country date variable_1 value ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; ## 1 lu 01/01/2005 maybe 22 ## 2 lu 01/07/2005 maybe 13 ## 3 lu 01/01/2006 maybe 40 ## 4 lu 01/07/2006 maybe 25 ## 5 lu 01/01/2005 totally_agree 42 ## 6 lu 01/07/2005 totally_agree 17 ## 7 lu 01/01/2006 totally_agree 25 ## 8 lu 01/07/2006 totally_agree 16 ## 9 lu 01/01/2005 totally_disagree 39 ## 10 lu 01/07/2005 totally_disagree 17 ## 11 lu 01/01/2006 totally_disagree 23 ## 12 lu 01/07/2006 totally_disagree 21 ## 13 lu 01/01/2005 kinda_disagree 69 ## 14 lu 01/07/2005 kinda_disagree 12 ## 15 lu 01/01/2006 kinda_disagree 10 ## 16 lu 01/07/2006 kinda_disagree 9 ## 17 lu 01/01/2005 kinda_agree 38 ## 18 lu 01/07/2005 kinda_agree 31 ## 19 lu 01/01/2006 kinda_agree 19 ## 20 lu 01/07/2006 kinda_agree 12 ## # A tibble: 20 x 4 ## country date variable_2 value ## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; ## 1 lu 01/01/2005 kinda_agree 22 ## 2 lu 01/07/2005 kinda_agree 13 ## 3 lu 01/01/2006 kinda_agree 40 ## 4 lu 01/07/2006 kinda_agree 25 ## 5 lu 01/01/2005 totally_agree 42 ## 6 lu 01/07/2005 totally_agree 17 ## 7 lu 01/01/2006 totally_agree 25 ## 8 lu 01/07/2006 totally_agree 16 ## 9 lu 01/01/2005 totally_disagree 39 ## 10 lu 01/07/2005 totally_disagree 17 ## 11 lu 01/01/2006 totally_disagree 23 ## 12 lu 01/07/2006 totally_disagree 21 ## 13 lu 01/01/2005 maybe 69 ## 14 lu 01/07/2005 maybe 12 ## 15 lu 01/01/2006 maybe 10 ## 16 lu 01/07/2006 maybe 9 ## 17 lu 01/01/2005 kinda_disagree 38 ## 18 lu 01/07/2005 kinda_disagree 31 ## 19 lu 01/01/2006 kinda_disagree 19 ## 20 lu 01/07/2006 kinda_disagree 12 As explained in Hadley (2014), this is how you should keep your data… But for a particular purpose, I had to transform these datasets.</description>
    </item>
    
    <item>
      <title>Lesser known dplyr 0.7* tricks</title>
      <link>/blog/2017-06-19-dplyr-0-70-tutorial/</link>
      <pubDate>Sun, 02 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-06-19-dplyr-0-70-tutorial/</guid>
      <description>This blog post is an update to an older one I wrote in March. In the post from March, dplyr was at version 0.50, but since then a major update introduced some changes that make some of the tips in that post obsolete. So here I revisit the blog post from March by using dplyr 0.70.
Create new columns with mutate() and case_when() The basic things such as selecting columns, renaming them, filtering, etc did not change with this new version.</description>
    </item>
    
    <item>
      <title>Make ggplot2 purrr</title>
      <link>/blog/2017-03-29-make-ggplot2-purrr/</link>
      <pubDate>Wed, 29 Mar 2017 06:45:48 +0200</pubDate>
      
      <guid>/blog/2017-03-29-make-ggplot2-purrr/</guid>
      <description>Update: I’ve included another way of saving a separate plot by group in this article, as pointed out by @monitus. Actually, this is the preferred solution; using dplyr::do() is deprecated, according to Hadley Wickham himself.
I’ll be honest: the title is a bit misleading. I will not use purrr that much in this blog post. Actually, I will use one single purrr function, at the very end. I use dplyr much more.</description>
    </item>
    
    <item>
      <title>Introducing brotools</title>
      <link>/blog/2017-03-27-introducing_brotools/</link>
      <pubDate>Mon, 27 Mar 2017 09:23:56 +0200</pubDate>
      
      <guid>/blog/2017-03-27-introducing_brotools/</guid>
      <description>I’m happy to announce my first R package, called brotools. This is a package that contains functions that are specific to my needs but that you might find also useful. I blogged about some of these functions, so if you follow my blog you might already be familiar with some of them. It is not on CRAN and might very well never be. The code is hosted on bitbucket and you can install the package with</description>
    </item>
    
    <item>
      <title>Lesser known purrr tricks</title>
      <link>/blog/2017-03-24-lesser_known_purrr/</link>
      <pubDate>Fri, 24 Mar 2017 12:00:00 +0100</pubDate>
      
      <guid>/blog/2017-03-24-lesser_known_purrr/</guid>
      <description>purrr is a package that extends R’s functional programming capabilities. It brings a lot of new stuff to the table and in this post I show you some of the most useful (at least to me) functions included in purrr.
Getting rid of loops with map() library(purrr) numbers &amp;lt;- list(11, 12, 13, 14) map_dbl(numbers, sqrt) ## [1] 3.316625 3.464102 3.605551 3.741657 You might wonder why this might be preferred to a for loop?</description>
    </item>
    
    <item>
      <title>Lesser known dplyr tricks</title>
      <link>/blog/2017-02-17-lesser_known_tricks/</link>
      <pubDate>Wed, 08 Mar 2017 12:00:00 +0100</pubDate>
      
      <guid>/blog/2017-02-17-lesser_known_tricks/</guid>
      <description>In this blog post I share some lesser-known (at least I believe they are) tricks that use mainly functions from dplyr.
Removing unneeded columns Did you know that you can use - in front of a column name to remove it from a data frame?
mtcars %&amp;gt;% select(-disp) %&amp;gt;% head() ## mpg cyl hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.</description>
    </item>
    
    <item>
      <title>How to use jailbreakr</title>
      <link>/blog/2017-02-17-how_to_use_jailbreakr/</link>
      <pubDate>Fri, 17 Feb 2017 12:51:00 +0100</pubDate>
      
      <guid>/blog/2017-02-17-how_to_use_jailbreakr/</guid>
      <description>What is jailbreakr The jailbreakr package is probably one of the most interesting packages I came across recently. This package makes it possible to extract messy data from spreadsheets. What is meant by messy? I am sure you already had to deal with spreadsheets that contained little tables inside a single sheet for example. As far as I know, there is no simple way of extracting these tables without having to fiddle around a lot.</description>
    </item>
    
    <item>
      <title>Functional programming and unit testing for data munging with R available on Leanpub</title>
      <link>/blog/2016-12-24-functional-programming-and-unit-testing-for-data-munging-with-r-available-on-leanpub/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-12-24-functional-programming-and-unit-testing-for-data-munging-with-r-available-on-leanpub/</guid>
      <description>The book I&amp;rsquo;ve been working on these pasts months (you can read about it here, and read it for free here) is now available on Leanpub! You can grab a copy and read it on your ebook reader or on your computer, and what&amp;rsquo;s even better is that it is available for free (but you can also decide to buy it if you really like it). Here is the link on Leanpub.</description>
    </item>
    
    <item>
      <title>My free book has a cover!</title>
      <link>/blog/2017-01-07-my-free-book-has-a-cover/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2017-01-07-my-free-book-has-a-cover/</guid>
      <description>I&amp;rsquo;m currently writing a book as a hobby. It&amp;rsquo;s titled Functional programming and unit testing for data munging with R and you can get it for free here. You can also read it online for free on my webpage What&amp;rsquo;s the book about?
Here&amp;rsquo;s the teaser text:
 Learn the basics of functional programming, unit testing and package development for the R programming language in order to make your data tidy!</description>
    </item>
    
    <item>
      <title>Work on lists of datasets instead of individual datasets by using functional programming</title>
      <link>/blog/2016-12-21-work-on-lists-of-datasets-instead-of-individual-datasets-by-using-functional-programming/</link>
      <pubDate>Wed, 21 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-12-21-work-on-lists-of-datasets-instead-of-individual-datasets-by-using-functional-programming/</guid>
      <description>Analyzing a lot of datasets can be tedious. In my work, I often have to compute descriptive statistics, or plot some graphs for some variables for a lot of datasets. The variables in question have the same name accross the datasets but are measured for different years. As an example, imagine you have this situation:
data2000 &amp;lt;- mtcars data2001 &amp;lt;- mtcars For the sake of argument, imagine that data2000 is data from a survey conducted in the year 2000 and data2001 is the same survey but conducted in the year 2001.</description>
    </item>
    
    <item>
      <title>I&#39;ve started writing a &#39;book&#39;: Functional programming and unit testing for data munging with R</title>
      <link>/blog/2016-11-04-ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r/</link>
      <pubDate>Fri, 04 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-11-04-ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r/</guid>
      <description>I have started writing a &amp;lsquo;book&amp;rsquo; using the awesome bookdown package. In the book I explain and show why using functional programming and putting your functions in your own packages is the way to go when you want to clean, prepare and transform large data sets. It makes testing and documenting your code easier. You don&amp;rsquo;t need to think about managing paths either. The book is far from complete, but I plan on working on it steadily.</description>
    </item>
    
    <item>
      <title>Merge a list of datasets together</title>
      <link>/blog/2016-07-30-merge-a-list-of-datasets-together/</link>
      <pubDate>Sat, 30 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-07-30-merge-a-list-of-datasets-together/</guid>
      <description>Last week I showed how to read a lot of datasets at once with R, and this week I’ll continue from there and show a very simple function that uses this list of read datasets and merges them all together.
First we’ll use read_list() to read all the datasets at once (for more details read last week’s post):
library(&amp;quot;readr&amp;quot;) library(&amp;quot;tibble&amp;quot;) data_files &amp;lt;- list.files(pattern = &amp;quot;.csv&amp;quot;) print(data_files) ## [1] &amp;quot;data_1.csv&amp;quot; &amp;quot;data_2.csv&amp;quot; &amp;quot;data_3.</description>
    </item>
    
    <item>
      <title>Read a lot of datasets at once with R</title>
      <link>/blog/2016-07-26-read-a-lot-of-datasets-at-once-with-r/</link>
      <pubDate>Tue, 26 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-07-26-read-a-lot-of-datasets-at-once-with-r/</guid>
      <description>I often have to read a lot of datasets at once using R. So I’ve wrote the following function to solve this issue:
read_list &amp;lt;- function(list_of_datasets, read_func){ read_and_assign &amp;lt;- function(dataset, read_func){ dataset_name &amp;lt;- as.name(dataset) dataset_name &amp;lt;- read_func(dataset) } # invisible is used to suppress the unneeded output output &amp;lt;- invisible( sapply(list_of_datasets, read_and_assign, read_func = read_func, simplify = FALSE, USE.NAMES = TRUE)) # Remove the extension at the end of the data set names names_of_datasets &amp;lt;- c(unlist(strsplit(list_of_datasets, &amp;quot;[.</description>
    </item>
    
    <item>
      <title>Data frame columns as arguments to dplyr functions</title>
      <link>/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/</link>
      <pubDate>Mon, 18 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/</guid>
      <description>Suppose that you would like to create a function which does a series of computations on a data frame. You would like to pass a column as this function’s argument. Something like:
data(cars) convertToKmh &amp;lt;- function(dataset, col_name){ dataset$col_name &amp;lt;- dataset$speed * 1.609344 return(dataset) } This example is obviously not very interesting (you don’t need a function for this), but it will illustrate the point. You would like to append a column called speed_in_kmh with the speed in kilometers per hour to this dataset, but this is what happens:</description>
    </item>
    
    <item>
      <title>Careful with tryCatch</title>
      <link>/blog/2016-06-21-careful-with-trycatch/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-06-21-careful-with-trycatch/</guid>
      <description>tryCatch is one of the functions that allows the users to handle errors in a simple way. With it, you can do things like: if(error), then(do this).
Take the following example:
sqrt(&amp;quot;a&amp;quot;) Error in sqrt(&amp;quot;a&amp;quot;) : non-numeric argument to mathematical function Now maybe you’d want something to happen when such an error happens. You can achieve that with tryCatch:
tryCatch(sqrt(&amp;quot;a&amp;quot;), error=function(e) print(&amp;quot;You can&#39;t take the square root of a character, silly!</description>
    </item>
    
    <item>
      <title>Unit testing with R</title>
      <link>/blog/2016-03-31-unit-testing-with-r/</link>
      <pubDate>Thu, 31 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>/blog/2016-03-31-unit-testing-with-r/</guid>
      <description>I&amp;#39;ve been introduced to unit testing while working with colleagues on quite a big project for which we use Python.
At first I was a bit skeptical about the need of writing unit tests, but now I must admit that I am seduced by the idea and by the huge time savings it allows. Naturally, I was wondering if the same could be achieved with R, and was quite happy to find out that it also possible to write unit tests in R using a package called testthat.</description>
    </item>
    
    <item>
      <title>Bootstrapping standard errors for difference-in-differences estimation with R</title>
      <link>/blog/2015-11-11-bootstrapping-did-with-r/</link>
      <pubDate>Wed, 11 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015-11-11-bootstrapping-did-with-r/</guid>
      <description>I’m currently working on a paper (with my colleague Vincent Vergnat who is also a Phd candidate at BETA) where I want to estimate the causal impact of the birth of a child on hourly and daily wages as well as yearly worked hours. For this we are using non-parametric difference-in-differences (henceforth DiD) and thus have to bootstrap the standard errors. In this post, I show how this is possible using the function boot.</description>
    </item>
    
    <item>
      <title>Update to Introduction to programming econometrics with R</title>
      <link>/blog/2015-05-03-update-introduction-r-programming/</link>
      <pubDate>Sun, 03 May 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015-05-03-update-introduction-r-programming/</guid>
      <description>This semester I taught a course on applied econometrics with the R programming language. For this, I created a document that I gave to my students and shared online. This is the kind of document I would have liked to read when I first started using R. I already had some programming experience in C and Pascal but this is not necessarily the case for everyone that is confronted to R when they start learning about econometrics.</description>
    </item>
    
    <item>
      <title>Export R output to a file</title>
      <link>/blog/2015-02-22-export-r-output-to-file/</link>
      <pubDate>Sun, 22 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015-02-22-export-r-output-to-file/</guid>
      <description>Sometimes it is useful to export the output of a long-running R command. For example, you might want to run a time consuming regression just before leaving work on Friday night, but would like to get the output saved inside your Dropbox folder to take a look at the results before going back to work on Monday.
This can be achieved very easily using capture.output() and cat() like so:</description>
    </item>
    
    <item>
      <title>Introduction to programming econometrics with R</title>
      <link>/blog/2015-01-12-introduction-to-programming-econometrics-with-r/</link>
      <pubDate>Mon, 12 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>/blog/2015-01-12-introduction-to-programming-econometrics-with-r/</guid>
      <description>This semester, I&amp;rsquo;ll be teaching an introduction to applied econometrics with R, so I&amp;rsquo;ve decided to write a very small book called &amp;ldquo;Introduction to programming Econometrics with R&amp;rdquo;. This is primarily intended for bachelor students and the focus is not much on econometric theory, but more on how to implement econometric theory into computer code, using the R programming language. It&amp;rsquo;s very basic and doesn&amp;rsquo;t cover any advanced topics in econometrics and is intended for people with 0 previous programming knowledge.</description>
    </item>
    
    <item>
      <title>R, R with Atlas, R with OpenBLAS and Revolution R Open: which is fastest?</title>
      <link>/blog/2014-11-11-benchmarks-r-blas-atlas-rro/</link>
      <pubDate>Tue, 11 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>/blog/2014-11-11-benchmarks-r-blas-atlas-rro/</guid>
      <description>In this short post, I benchmark different &amp;ldquo;versions&amp;rdquo; of R. I compare the execution speeds of R, R linked against OpenBLAS, R linked against ATLAS and Revolution R Open. Revolution R Open is a new open source version of R made by Revolution Analytics. It is linked against MKL and should offer huge speed improvements over vanilla R. Also, it uses every cores of your computer by default, without any change whatsoever to your code.</description>
    </item>
    
    <item>
      <title>Object Oriented Programming with R: An example with a Cournot duopoly</title>
      <link>/blog/2014-04-23-r-s4-rootfinding/</link>
      <pubDate>Wed, 23 Apr 2014 00:00:00 +0000</pubDate>
      
      <guid>/blog/2014-04-23-r-s4-rootfinding/</guid>
      <description>I started reading Applied Computational Economics &amp;amp; Finance by Mario J. Miranda and Paul L. Fackler. It is a very interesting book that I recommend to every one of my colleagues. The only issue I have with this book, is that the programming language they use is Matlab, which is proprietary. While there is a free as in freedom implementation of the Matlab language, namely Octave, I still prefer using R.</description>
    </item>
    
    <item>
      <title>Using R as a Computer Algebra System with Ryacas</title>
      <link>/blog/2013-12-31-r-cas/</link>
      <pubDate>Tue, 31 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013-12-31-r-cas/</guid>
      <description>R is used to perform statistical analysis and doesn&amp;#39;t focus on symbolic maths. But it is sometimes useful to let the computer derive a function for you (and have the analytic expression of said derivative), but maybe you don&amp;#39;t want to leave your comfy R shell. It is possible to turn R into a full-fledged computer algebra system. CASs are tools that perform symbolic operations, such as getting the expression of the derivative of a user-defined (and thus completely arbitrary) function.</description>
    </item>
    
    <item>
      <title>Method of Simulated Moments with R</title>
      <link>/blog/2013-01-29-method-of-simulated-moments-with-r/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013-01-29-method-of-simulated-moments-with-r/</guid>
      <description>This document details section 12.5.6. Unobserved Heterogeneity Example. The original source code giving the results from table 12.3 are available from the authors&amp;#39; site here and written for Stata. This is an attempt to translate the code to R.
Consult the original source code if you want to read the authors&amp;#39; comments. If you want the R source code without all the commentaries, grab it here. This is not guaranteed to work, nor to be correct.</description>
    </item>
    
    <item>
      <title>Simulated Maximum Likelihood with R</title>
      <link>/blog/2013-01-16-simulated-maximum-likelihood-with-r/</link>
      <pubDate>Wed, 11 Dec 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013-01-16-simulated-maximum-likelihood-with-r/</guid>
      <description>This document details section 12.4.5. Unobserved Heterogeneity Example from Cameron and Trivedi&#39;s book - MICROECONOMETRICS: Methods and Applications. The original source code giving the results from table 12.2 are available from the authors&amp;#39; site here and written for Stata. This is an attempt to translate the code to R. I&#39;d like to thank Reddit user anonemouse2010 for his advice which helped me write the function.
Consult the original source code if you want to read the authors&amp;#39; comments.</description>
    </item>
    
    <item>
      <title>Nonlinear Gmm with R - Example with a logistic regression</title>
      <link>/blog/2013-11-07-gmm-with-rmd/</link>
      <pubDate>Thu, 07 Nov 2013 00:00:00 +0000</pubDate>
      
      <guid>/blog/2013-11-07-gmm-with-rmd/</guid>
      <description>In this post, I will explain how you can use the R gmm package to estimate a non-linear model, and more specifically a logit model. For my research, I have to estimate Euler equations using the Generalized Method of Moments. I contacted Pierre Chaussé, the creator of the gmm library for help, since I was having some difficulties. I am very grateful for his help (without him, I&amp;#39;d still probably be trying to estimate my model!</description>
    </item>
    
    <item>
      <title>New website!</title>
      <link>/blog/2012-12-11-new-website/</link>
      <pubDate>Tue, 11 Dec 2012 00:00:00 +0000</pubDate>
      
      <guid>/blog/2012-12-11-new-website/</guid>
      <description>This is my new website! It&amp;rsquo;s built using jekyll-bootstrap and hosted on Github.</description>
    </item>
    
    <item>
      <title>index</title>
      <link>/</link>
      <pubDate>Sat, 01 Jan 2000 19:50:00 +0200</pubDate>
      
      <guid>/</guid>
      <description>Welcome  Hi! My name is Bruno Rodrigues, and I&amp;rsquo;m a research assistant at STATEC.
I program mostly in R and love sharing my knowledge, that&amp;rsquo;s why I started this blog. I share my posts also on R-bloggers. In my posts, I discuss new packages I discovered or new ways of using packages.
If you were one of my students, and need some of the materials I taught, just drop me an email.</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/about/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/projects/</guid>
      <description>Functional programming and unit testing for data munging with R I am currently writing a book about functional programming, unit testing and package development with R. You can read it for free here and you can buy a digital copy at leanpub.
Gumbel Linux I am developing a custom GNU+Linux iso aimed at statisticians/data scientists/econometricians. It&amp;rsquo;ll have everything needed pre-installed. I did this in the past already, by using Suse Studio.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>/about/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/research/</guid>
      <description>Published Articles Version Control Systems to Facilitate Research Collaboration in Economics, in Computational Economics, 2015 Abstract
Reliable and reproducible research is an important cornerstone of science, and version control systems not only make reproducible research possible in a rapid and easy way, but also provide a way of collaborating with co-authors. The purpose of this methodological paper is to present Git, a very successful version control system and how it can be used by economists working together on their papers and the accompanying computer code.</description>
    </item>
    
    <item>
      <title>Software</title>
      <link>/about/software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/software/</guid>
      <description>This is a list of software I use for work. I only use Free Software (whenever I have a choice, at least). Free here is not about price, but about freedom. Think of free as in free speech. The reasons I chose to use free software are both practical and philosophical. Free software gives me infinite flexibility: I can install it on any machine I own without having to worry about licenses or worry that the software may become deprecated some day.</description>
    </item>
    
    <item>
      <title>Who am I?</title>
      <link>/about/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/about/</guid>
      <description>My name is Bruno Rodrigues and I am a PhD candidate at the Bureau d’économie Théorique et Appliquée at the University of Strasbourg. My thesis advisor is Bertrand Kœbel and my co-advisor is François Laisney.
I started working at STATEC, which is the national statistical office of the Grand-Duchy of Luxembourg in July 2016. I&amp;rsquo;m part of the research division and my main mission is assisting the researchers with data issues.</description>
    </item>
    
  </channel>
</rss>