---
date: 2018-06-10
title: "Getting data from pdfs using the pdftools package"
tags: [R]
menu:
  main:
    parent: Blog
    identifier: /blog/scraping_pdfs
    weight: 1
---

It is often the case that data is trapped inside pdfs, but thankfully there are ways to extract
it from the pdfs. A very nice package for this task is 
`pdftools` ([Github link](https://github.com/ropensci/pdftools))
and this blog post will describe some basic functionality from that package.

First, let's find some pdfs that contain interesting data. For this post, I'm using the diabetes
country profiles from the World Health Organization. You can find them [here](http://www.who.int/diabetes/country-profiles/en/#U).
If you open one of these pdfs, you are going to see this:

<div style="text-align:center;">
  <a href="http://www.who.int/diabetes/country-profiles/lux_en.pdf?ua=1">
    <img src="/img/diabetes_lux.png" width="499" height="680"/></a>
</div>

I'm interested in this table here in the middle:

<div style="text-align:center;">
  <a href="http://www.who.int/diabetes/country-profiles/lux_en.pdf?ua=1">
    <img src="/img/diabetes_table.png" width="499" height="680"/></a>
</div>

I want to get the data from different countries, put it all into a nice data frame and make a 
simple plot. 

Let's first start by loading the needed packages:

```{r, cache=TRUE}
library("pdftools")
library("glue")
library("tidyverse")
library("ggthemes")

country <- c("lux", "fra", "deu", "usa", "prt", "gbr")

url <- "http://www.who.int/diabetes/country-profiles/{country}_en.pdf?ua=1"
```

The first 4 lines load the needed packages for this exercise: `pdftools` is the package that I 
described in the beginning of the post, `glue` is optional but offers a nice alternative to the 
`paste()` and `paste0()` functions. Take a closer look at the url: you'll see that I wrote `{country}`.
This is not in the original links; the original links look like this (for example for the USA):

```
"http://www.who.int/diabetes/country-profiles/usa_en.pdf?ua=1"
```

So because I'm interested in several countries, I created a vector with the country codes 
of the countries I'm interested in. Now, using the `glue()` function, something magical happens:

```{r, cache=TRUE}
(urls <- glue(url))
```

This created a vector with all the links where `{country}` is replaced by each of the codes 
contained in the variable `country`.

I use the same trick to create the names of the pdfs that I will download:

```{r, cache=TRUE}
pdf_names <- glue("report_{country}.pdf")
```

And now I can download them:

```{r, cache=TRUE}
walk2(urls, pdf_names, download.file, mode = "wb")
```

`walk2()` is a function from the `purrr` package that is similar to `map2()`. You could use `map2()` 
for this, but `walk2()` is cleaner here, because `dowload.file()` is a function with a so-called
side effect; it downloads files. `map2()` is used for functions without side effects.

Now, I can finally use the `pdf_text()` function from the `pdftools` function to get the text
from the pdfs:

```{r, cache=TRUE}
raw_text <- map(pdf_names, pdf_text)
```

`raw_text` is a list of where each element is the text from one of the pdfs. Let's take a look:

```{r, cache=TRUE}
str(raw_text)
```

Let's take a look at one of these elements, which is nothing but a very long character:

```{r, cache=TRUE}
raw_text[[1]]
```

As you can see, this is a very long character string with some line breaks (the `"\n"` character). 
So first, we need to split this string into a character vector by the `"\n"` character. Also, it might
be difficult to see, but the table starts at the line with the following string:
`"Prevalence of diabetes"` and ends with `"National response to diabetes"`. Also, we need to get 
the name of the country from the text and add it as a column. As you can see, a whole lot 
of operations are needed, so what I do is put all these operations into a function that I will apply
to each element of `raw_text`:


```{r, cache=TRUE}
clean_table <- function(table){
    table <- str_split(table, "\n", simplify = TRUE)
    country_name <- table[1, 1] %>% 
        stringr::str_squish() %>% 
        stringr::str_extract(".+?(?=\\sTotal)")
    table_start <- stringr::str_which(table, "Prevalence of diabetes")
    table_end <- stringr::str_which(table, "National response to diabetes")
    table <- table[1, (table_start +1 ):(table_end - 1)]
    table <- str_replace_all(table, "\\s{2,}", "|")
    text_con <- textConnection(table)
    data_table <- read.csv(text_con, sep = "|")
    colnames(data_table) <- c("Condition", "Males", "Females", "Total")
    dplyr::mutate(data_table, Country = country_name)
}
```

I advise you to go through all these operations and understand what each does. However, I will 
describe some of the lines, such as this one:

```
stringr::str_extract(".+?(?=\\sTotal)")
```

This uses a very bizarre looking regular expression: `".+?(?=\\sTotal)"`. This extracts everything
before a space, followed by the string `"Total"`. This is because the first line, the one that contains
the name of the country looks like this: `"Luxembourg Total population: 567 000\n"`. So everything
before a space followed by the word `"Total"` is the country name. Then there's these lines:

```
table <- str_replace_all(table, "\\s{2,}", "|")
text_con <- textConnection(table)
data_table <- read.csv(text_con, sep = "|")
```

The first lines replaces 2 spaces or more ("`\\s{2,}`") with `"|"`. The reason I do this is because 
then I can read the table back into R as a data frame by specifying the separator as the "|" character.
On the second line, I define `table` as a text connection, that I can then read back into R using 
`read.csv()`. On the second to the last line I change the column names and then I add a column
called `"Country"` to the data frame.

Now, I can map this useful function to the list of raw text extracted from the pdfs:

```{r, warning=FALSE, cache=TRUE}
diabetes <- map_df(raw_text, clean_table) %>% 
    gather(Sex, Share, Males, Females, Total) %>% 
    mutate(Share = as.numeric(str_extract(Share, "\\d{1,}\\.\\d{1,}")))
```

I reshape the data with the `gather()` function (see what the data looks like before and after 
reshaping). I then convert the `"Share"` column into a numeric (it goes from something that looks
like `"12.3 %"` into `12.3`) and then I can create a nice plot. But first let's take a look at 
the data:

```{r, cache=TRUE}
diabetes
```

Now let's go for the plot:

```{r, cache=TRUE}
ggplot(diabetes) + theme_fivethirtyeight() + scale_fill_hc() +
    geom_bar(aes(y = Share, x = Sex, fill = Country), 
             stat = "identity", position = "dodge") +
    facet_wrap(~Condition)
```

That was a whole lot of work for such a simple plot!

If you found this blog post useful, you might want to follow me on [twitter](https://www.twitter.com/brodriguesco)
for blog post updates.




