---
date: 2018-06-24
title: "Forecasting my weight with R"
tags: [R]
menu:
  main:
    parent: Blog
    identifier: /blog/forecast_weight
    weight: 1
---

I've been measuring my weight almost daily for almost 2 years now; I actually started earlier, but
not as consistently. The goal of this blog post is to get re-acquaiented with time series; I haven't
had the opportunity to work with time series for a long time now and I have seen that quite a few
packages that deal with time series have been released on CRAN. In this blog post, I will explore
my weight measurements using some functions from the `{tsibble}` and `{tibbletime}` packages, 
and then do some predictions with the `{forecast}` package.

First, let's load the needed packages, read in the data and convert it to a `tsibble`:

```{r, include=FALSE}
library("tidyverse")
library("readr")
library("forecast")
library("tsibble")
library("tibbletime")
library("mice")
```


```{r, eval=FALSE}
library("tidyverse")
library("readr")
library("forecast")
library("tsibble")
library("tibbletime")
library("mice")
```

```{r}
weight <- read_csv("https://gist.githubusercontent.com/b-rodrigues/ea60679135f8dbed448ccf66a216811f/raw/18b469f3b0720f76ce5ee2715d0f9574b615f170/gistfile1.txt") %>% 
    as_tsibble()
```

You can read more about `{tsibble}` [here](https://pkg.earo.me/tsibble/). Here, I use `{tsibble}` mostly
for the next step, which is using the function `fill_na()` on the tsibble. `fill_na()` turns
implicit missing values into explicit missing values. These are implicit missing values:

```
          Date Poids
1   2013-01-01 84.10
2   2013-01-04 85.60
```

and this is the same view, but with explicit missing values:

```
          Date Poids
1   2013-01-01 84.10
2   2013-01-02 NA
3   2013-01-03 NA
4   2013-01-04 85.60
```
This is useful to do, because I want to impute the missing values using the `{mice}` package. 
Let's do this:

```{r}
weight <- weight %>% 
    fill_na()

imp_weight <- mice(data = weight) %>% 
    mice::complete("long")
```

Let's take a look at `imp_weight`:

```{r}
head(imp_weight)
```

Let's select the relevant data. I filter from the 11th of July 2016, which is where I started 
weighing myself almost every day, to the 31st of May 2018. I want to predict my weight for the
month of June (you might think of the month of June 2018 as the test data, and the rest as training
data):

```{r}
imp_weight_train <- imp_weight %>% 
    filter(Date >= "2016-07-11", Date <= "2018-05-31")
```

In the next lines, I create a column called `imputation` which is simply the same as the column
`.imp` but of character class, remove unneeded columns and rename some other columns ("Poids" is 
French for weight):

```{r}
imp_weight_train <- imp_weight_train %>% 
    mutate(imputation = as.character(.imp)) %>% 
    select(-.id, -.imp) %>% 
    rename(date = Date) %>% 
    rename(weight = Poids)
```

Let's take a look at the data:

```{r}
ggplot(imp_weight_train, aes(date, weight, colour = imputation)) +
    geom_line() + 
    theme(legend.position = "bottom")
```

This plots gives some info, but it might be better to smooth the lines. This is possible by 
computing a rolling mean. For this I will use the `rollify()` function of the `{tibbletime}` package:

```{r}
mean_roll_5 <- rollify(mean, window = 5)
mean_roll_10 <- rollify(mean, window = 10)
```

`rollify()` can be seen as an adverb, pretty much like `purrr::safely()`; `rollify()` is a higher 
order function that literally rollifies a function, in this case `mean()` which means that 
rollifying the mean creates a function that returns the rolling mean. The `window` argument lets 
you decide how smooth you want the curve to be: the higher the smoother. However, you will lose 
some observations. Let's use this functions to add the rolling means to the data frame:

```{r}
imp_weight_train <- imp_weight_train %>% 
    group_by(imputation) %>% 
    mutate(roll_5 = mean_roll_5(weight),
           roll_10 = mean_roll_10(weight))
```

Now, let's plot these new curves:

```{r}
ggplot(imp_weight_train, aes(date, roll_5, colour = imputation)) +
    geom_line() + 
    theme(legend.position = "bottom")


ggplot(imp_weight_train, aes(date, roll_10, colour = imputation)) +
    geom_line() + 
    theme(legend.position = "bottom")
```

That's easier to read, isn't it?

Now, I will use the `auto.arima()` function to train a model on the data to forecast my weight for
the month of June. However, my data, `imp_weight_train` is a list of datasets. `auto.arima()` does 
not take a data frame as an argument, much less so a list of datasets. I'll create a wrapper around
`auto.arima()` that works on a dataset, and then map it to the list of datasets:


```{r}
auto.arima.df <- function(data, y, ...){

    y <- enquo(y)

    yts <- data %>% 
        pull(!!y) %>% 
        as.ts()

    auto.arima(yts, ...)
}
```

`auto.arima.df()` takes a data frame as argument, and then `y`, which is the column that contains the
univariate time series. This column then gets pulled out of the data frame, converted to a time
series object with `as.ts()`, and then passed down to `auto.arima()`. I can now use this function
on my list of data sets. The first step is to nest the data:

```{r}
nested_data <- imp_weight_train %>% 
    group_by(imputation) %>% 
    nest() 
```

Let's take a look at `nested_data`:

```{r}
nested_data
```

`nested_data` is a tibble with a column called `data`, which is a so-called list-column. Each
element of `data` is itself a tibble. This is a useful structure, because now I can map `auto.arima.df()`
to the data frame:

```{r}
models <- nested_data %>% 
    mutate(model = map(data, auto.arima.df, y = weight))
```

This trick can be a bit difficult to follow the first time you see it. The idea is the following:
`nested_data` is a tibble. Thus, I can add a column to it using `mutate()`. So far so good.
Now that I am "inside" the mutate call, I can use `purrr::map()`. Why? `purrr::map()` takes a list
and then a function as arguments. Remember that `data` is a list column; you can see it above, 
the type of the column `data` is list. So `data` is a list, and thus can be used inside `purrr::map()`.
Great. Now, what is inside `data`? tibbles, where inside each of them is a column
called `weight`. This is the column that contains my univariate time series I want to model. Let's
take a look at `models`:

```{r}
models
```

`models` is a tibble with a column called `model`, where each element is a model of type `ARIMA`.

Adding forecasts is based on the same trick as above, and we use the `forecast()` function:

```{r}
forecasts <- models %>% 
    mutate(predictions = map(model, forecast, h = 24)) %>% 
    mutate(predictions = map(predictions, as_tibble)) %>% 
    pull(predictions) 
```

I forecast 24 days (I am writing this on the 24th of June), and convert the predictions to tibbles,
and then pull only the predictions tibble:

```{r}
forecasts
```

So `forecasts` is a list of tibble, each containing a forecast. Remember that I have 5 tibbles, because
I imputed the data 5 times. I will merge this list of data sets together into one, but before I need
to add a column that indices the forecasts:

```{r}
forecasts <- map2(.x = forecasts, .y = as.character(seq(1, 5)), 
     ~mutate(.x, id = .y)) %>% 
    bind_rows() %>% 
    select(-c(`Lo 80`, `Hi 80`))

colnames(forecasts) <- c("point_forecast", "low_95", "hi_95", "id")
```

Let's take a look again at `forecasts`:

```{r}
forecasts
```

I now select the true values for the month of June. I also imputed this data, but here I will 
simply keep the average of the imputations:

```{r}
weight_june <- imp_weight %>% 
    filter(Date >= "2018-06-01") %>% 
    select(-.id) %>% 
    group_by(Date) %>% 
    summarise(true_weight = mean(Poids)) %>% 
    rename(date = Date)
```

Let's take a look at `weight_june`:

```{r}
weight_june
```

Let's repeat `weight_june` 5 times, and add the index 1 to 5. Why? Because I want to merge the 
true data with the forecasts, and having the data in this form makes things easier:

```{r}
weight_june <- modify(list_along(1:5), ~`<-`(., weight_june)) %>% 
    map2(.y = as.character(seq(1, 5)), 
         ~mutate(.x, id = .y)) %>% 
    bind_rows()
```

The first line:

```
modify(list_along(1:5), ~`<-`(., weight_june)) 
```

looks quite complicated, but you will see that it is not, once we break it apart. `modify()` 
modifies a list. The list to modify is `list_along(1:5)`, which create a list of `NULL`s:

```{r}
list_along(1:5)
```

The second argument of `modify()` is either a function or a formula. I created the following 
formula:

```
~`<-`(., weight_june)
```

We all know the function `<-()`, but are not used to see it that way. But consider the following:

```{r}
a <- 3
```

```{r}
`<-`(a, 3)
```

These two formulations are equivalent. So these lines fill the empty element of the list of `NULL`s
with the data frame `weight_june`. Then I add the `id` column and then bind the rows together: `bind_rows()`.

Let's bind the columns of `weight_june` and `forecasts` and take a look at it:

```{r}
forecasts <- bind_cols(weight_june, forecasts) %>% 
    select(-id1)

forecasts
```

Now, for the last plot:

```{r}
ggplot(forecasts, aes(x = date, colour = id)) +
    geom_line(aes(y = true_weight), size = 2) + 
    geom_line(aes(y = hi_95)) + 
    geom_line(aes(y = low_95)) + 
    theme(legend.position = "bottom")
```

The true data fall within all the confidence intervals, but I am a bit surprised by the intervals, 
especially the upper confidence intervals; they all are way above 72kg, however my true weight
has been fluctuating around 71kg for quite some months now. I think I have to refresh my memory 
on time series, because I am certainly missing something!

If you found this blog post useful, you might want to follow me on [twitter](https://www.twitter.com/brodriguesco)
for blog post updates.




